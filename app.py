import streamlit as st
from rag_engine import SchoolChatbot
from tts_engine import text_to_speech, get_audio_base64
import os
import base64

# ============================================================
# ğŸ”§ 1. ì•± ì„¤ì •
# ============================================================
VRM_MODEL_URL = "https://raw.githubusercontent.com/sd40-teacher/school-chatbot/main/sdg1.vrm"

st.set_page_config(page_title="ì„±ê¸€ê³  AI ë„ìš°ë¯¸", page_icon="ğŸ«", layout="wide")

# API í‚¤ ë° ì±—ë´‡ ë¡œë“œ
try:
    api_key = st.secrets["OPENROUTER_API_KEY"]
except:
    st.error("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

@st.cache_resource
def load_chatbot():
    try:
        return SchoolChatbot(api_key=api_key, docs_path="data/school_docs")
    except:
        return None

chatbot = load_chatbot()

# ============================================================
# ğŸ”§ 2. ì•„ë°”íƒ€ & ì˜¤ë””ì˜¤ í†µí•© ë·°ì–´
# ============================================================
def vrm_viewer_component(audio_base64=None, refresh_count=0):
    # ì˜¤ë””ì˜¤ ì£¼ì… ë¡œì§
    audio_init_js = ""
    if audio_base64:
        audio_init_js = f"""
            const audio = document.getElementById("vrm-audio");
            audio.src = "data:audio/mp3;base64,{audio_base64}";
            // ìƒˆ ë‹µë³€ì´ ì˜¤ë©´ ë²„íŠ¼ì„ ê°•ì¡°
            const btn = document.getElementById("play-btn");
            btn.style.background = "#ff4b4b";
            btn.innerText = "â–¶ ë‹µë³€ ë“£ê¸°";
        """

    html_code = f"""
    <div style="width: 100%; height: 580px; background: #667eea; border-radius: 20px; position: relative; overflow: hidden; display: flex; flex-direction: column;">
        <canvas id="vrm-canvas" style="flex: 1; width: 100%; cursor: grab;"></canvas>
        
        <audio id="vrm-audio" style="display:none;"></audio>
        
        <div style="padding: 15px; background: rgba(0,0,0,0.2); display: flex; justify-content: center; align-items: center;">
            <button id="play-btn" style="
                padding: 12px 25px; font-size: 16px; font-weight: bold; cursor: pointer; 
                background: #4CAF50; color: white; border: none; border-radius: 10px; 
                box-shadow: 0 4px 10px rgba(0,0,0,0.2); transition: 0.2s;">
                {"ğŸ”ˆ ë‹µë³€ ëŒ€ê¸° ì¤‘" if not audio_base64 else "â–¶ ë‹µë³€ ë“£ê¸° / ë‹¤ì‹œ ë“£ê¸°"}
            </button>
        </div>

        <div id="loading" style="position: absolute; top: 10px; left: 10px; color: white; font-family: sans-serif; font-size: 12px;">ëª¨ë¸ ë¡œë”© ì¤‘...</div>

        <script type="importmap">
        {{
            "imports": {{
                "three": "https://cdn.jsdelivr.net/npm/three@0.158.0/build/three.module.js",
                "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.158.0/examples/jsm/",
                "@pixiv/three-vrm": "https://cdn.jsdelivr.net/npm/@pixiv/three-vrm@3.1.3/lib/three-vrm.module.min.js"
            }}
        }}
        </script>

        <script type="module">
            import * as THREE from "three";
            import {{ GLTFLoader }} from "three/addons/loaders/GLTFLoader.js";
            import {{ OrbitControls }} from "three/addons/controls/OrbitControls.js";
            import {{ VRMLoaderPlugin }} from "@pixiv/three-vrm";

            let vrm = null;
            const scene = new THREE.Scene();
            const camera = new THREE.PerspectiveCamera(35, window.innerWidth/(window.innerHeight-60), 0.1, 100);
            camera.position.set(0, 1.4, 2.2);

            const renderer = new THREE.WebGLRenderer({{ canvas: document.getElementById("vrm-canvas"), antialias: true, alpha: true }});
            renderer.setSize(window.innerWidth, window.innerHeight - 60);
            renderer.setPixelRatio(window.devicePixelRatio);
            renderer.outputColorSpace = THREE.SRGBColorSpace;

            const controls = new OrbitControls(camera, renderer.domElement);
            controls.target.set(0, 1.2, 0);
            controls.update();

            scene.add(new THREE.AmbientLight(0xffffff, 1.0));
            const light = new THREE.DirectionalLight(0xffffff, 1.0);
            light.position.set(1, 2, 3);
            scene.add(light);

            const loader = new GLTFLoader();
            loader.register((parser) => new VRMLoaderPlugin(parser));
            loader.load("{VRM_MODEL_URL}", (gltf) => {{
                vrm = gltf.userData.vrm;
                scene.add(vrm.scene);
                vrm.scene.rotation.y = Math.PI;
                document.getElementById("loading").style.display = "none";
                {audio_init_js}
            }});

            const audio = document.getElementById("vrm-audio");
            const btn = document.getElementById("play-btn");
            
            // ë²„íŠ¼ í´ë¦­ ì´ë²¤íŠ¸
            btn.onclick = () => {{
                if(audio.src) {{
                    audio.currentTime = 0;
                    audio.play();
                    btn.style.background = "#666";
                    btn.innerText = "ğŸ’¬ ë‹µë³€ ì½ì–´ì£¼ëŠ” ì¤‘...";
                }}
            }};
            
            audio.onended = () => {{
                btn.style.background = "#4CAF50";
                btn.innerText = "ğŸ”„ ë‹¤ì‹œ ë“£ê¸°";
            }};

            const clock = new THREE.Clock();
            function animate() {{
                requestAnimationFrame(animate);
                const delta = clock.getDelta();
                if (vrm) {{
                    vrm.update(delta);
                    // ì˜¤ë””ì˜¤ê°€ ì¬ìƒ ì¤‘ì¼ ë•Œë§Œ ì… ì›€ì§ì„
                    if (!audio.paused && !audio.ended && vrm.expressionManager) {{
                        const t = Date.now() * 0.012;
                        const s = (Math.sin(t) + 1) * 0.5;
                        
                        // ëª¨ë“  ê°€ëŠ¥í•œ ì‰ì´í”„í‚¤ ì´ë¦„ì— ê°’ ì£¼ì…
                        const mouthKeys = ["aa", "oh", "Fcl_MTH_A", "Fcl_MTH_O"];
                        mouthKeys.forEach(k => {{
                            try {{ vrm.expressionManager.setValue(k, s * 0.5); }} catch(e) {{}}
                        }});
                    }} else if (vrm.expressionManager) {{
                        // ì¢…ë£Œ ì‹œ ì… ë‹¤ë¬¼ê¸°
                        ["aa","ih","ou","ee","oh","Fcl_MTH_A","Fcl_MTH_I","Fcl_MTH_U","Fcl_MTH_E","Fcl_MTH_O"].forEach(k => {{
                            try {{ vrm.expressionManager.setValue(k, 0); }} catch(e) {{}}
                        }});
                    }}
                }}
                controls.update();
                renderer.render(scene, camera);
            }}
            animate();
        </script>
    </div>
    """
    st.components.v1.html(html_code, height=600)

# ============================================================
# ğŸ”§ 3. ë©”ì¸ í™”ë©´ êµ¬ì„±
# ============================================================
st.title("ğŸ« ì„±ê¸€ê³  AI ë„ìš°ë¯¸")

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë´ ì£¼ì„¸ìš”. ğŸ˜Š"}]
if "current_audio" not in st.session_state:
    st.session_state.current_audio = None

col_chat, col_vrm = st.columns([3, 2])

with col_chat:
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]): st.markdown(msg["content"])

    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"): st.markdown(prompt)

        with st.chat_message("assistant"):
            response = chatbot.ask(prompt)
            st.markdown(response)
            
            # ìŒì„± ìƒì„±
            audio_bytes = text_to_speech(response)
            audio_base64 = get_audio_base64(audio_bytes)
            
            st.session_state.messages.append({"role": "assistant", "content": response})
            st.session_state.current_audio = audio_base64
            st.rerun()

with col_vrm:
    st.subheader("ğŸ­ AI ì•„ë°”íƒ€")
    # ì•„ë°”íƒ€ ì°½ ë‚´ë¶€ì— ì¬ìƒ/ë‹¤ì‹œë“£ê¸° ë²„íŠ¼ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    vrm_viewer_component(st.session_state.current_audio)

    with st.expander("â„¹ï¸ ì´ìš© ì•ˆë‚´"):
        st.write("1. ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ì•„ë°”íƒ€ê°€ ë‹µë³€ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.")
        st.write("2. ë‹µë³€ì´ ì™„ë£Œë˜ë©´ ì•„ë°”íƒ€ í•˜ë‹¨ì˜ **[â–¶ ë‹µë³€ ë“£ê¸°]** ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        st.write("3. ì… ëª¨ì–‘ê³¼ í•¨ê»˜ ìŒì„±ì´ ì¬ìƒë©ë‹ˆë‹¤.")
