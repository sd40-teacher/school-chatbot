import streamlit as st
from rag_engine import SchoolChatbot
from tts_engine import text_to_speech, get_audio_base64
import os
import base64

# ============================================================
# ğŸ”§ 1. ì•± ì„¤ì •
# ============================================================
VRM_MODEL_URL = "https://raw.githubusercontent.com/sd40-teacher/school-chatbot/main/sdg1.vrm"

st.set_page_config(page_title="ì„±ê¸€ê³  AI ë„ìš°ë¯¸", page_icon="ğŸ«", layout="wide")

try:
    api_key = st.secrets["OPENROUTER_API_KEY"]
except:
    st.error("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

@st.cache_resource
def load_chatbot():
    try:
        return SchoolChatbot(api_key=api_key, docs_path="data/school_docs")
    except Exception as e:
        return None

chatbot = load_chatbot()

# ============================================================
# ğŸ”§ 2. ì•„ë°”íƒ€ & ì˜¤ë””ì˜¤ í†µí•© ë·°ì–´ (ì¹´ë©”ë¼ ìœ ì§€ + Idle ë³µêµ¬)
# ============================================================
def vrm_viewer_component(audio_base64=None):
    audio_init_js = ""
    if audio_base64:
        audio_init_js = f"""
            const audio = document.getElementById("vrm-audio");
            audio.src = "data:audio/mp3;base64,{audio_base64}";
            const btn = document.getElementById("play-btn");
            btn.style.background = "#ff4b4b";
            btn.innerText = "â–¶ ë‹µë³€ ë“£ê¸° (í´ë¦­)";
        """

    html_code = f"""
    <div style="width: 100%; height: 620px; background: #8a94c8; border-radius: 20px; position: relative; overflow: hidden; display: flex; flex-direction: column;">
        <canvas id="vrm-canvas" style="width: 100%; height: 500px; cursor: grab;"></canvas>
        <audio id="vrm-audio" style="display:none;"></audio>
        
        <div style="height: 120px; background: #667eea; display: flex; justify-content: center; align-items: center;">
            <button id="play-btn" style="
                padding: 15px 40px; font-size: 18px; font-weight: bold; cursor: pointer; 
                background: #4CAF50; color: white; border: none; border-radius: 15px; 
                box-shadow: 0 4px 15px rgba(0,0,0,0.3); width: 85%;">
                {"ğŸ”ˆ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”" if not audio_base64 else "â–¶ ë‹µë³€ ë“£ê¸° / ë‹¤ì‹œ ë“£ê¸°"}
            </button>
        </div>

        <script type="importmap">
        {{
            "imports": {{
                "three": "https://cdn.jsdelivr.net/npm/three@0.158.0/build/three.module.js",
                "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.158.0/examples/jsm/",
                "@pixiv/three-vrm": "https://cdn.jsdelivr.net/npm/@pixiv/three-vrm@3.1.3/lib/three-vrm.module.min.js"
            }}
        }}
        </script>

        <script type="module">
            import * as THREE from "three";
            import {{ GLTFLoader }} from "three/addons/loaders/GLTFLoader.js";
            import {{ OrbitControls }} from "three/addons/controls/OrbitControls.js";
            import {{ VRMLoaderPlugin }} from "@pixiv/three-vrm";

            let vrm = null;
            const scene = new THREE.Scene();
            const canvas = document.getElementById("vrm-canvas");
            
            // [ì¹´ë©”ë¼ ê³ ì •] ì´ì „ ë²„ì „ì—ì„œ ì„±ê³µí–ˆë˜ ì•µê¸€ ìœ ì§€
            const camera = new THREE.PerspectiveCamera(30, canvas.clientWidth / canvas.clientHeight, 0.1, 100);
            camera.position.set(0, 1.3, 2.5); 

            const renderer = new THREE.WebGLRenderer({{ canvas: canvas, antialias: true, alpha: true }});
            renderer.setSize(canvas.clientWidth, canvas.clientHeight);
            renderer.setPixelRatio(window.devicePixelRatio);

            const controls = new OrbitControls(camera, renderer.domElement);
            controls.target.set(0, 1.2, 0); 
            controls.update();

            scene.add(new THREE.AmbientLight(0xffffff, 0.7));
            const light = new THREE.DirectionalLight(0xffffff, 1.0);
            light.position.set(1, 2, 3);
            scene.add(light);

            const loader = new GLTFLoader();
            loader.register((parser) => new VRMLoaderPlugin(parser));
            loader.load("{VRM_MODEL_URL}", (gltf) => {{
                vrm = gltf.userData.vrm;
                scene.add(vrm.scene);
                vrm.scene.rotation.y = Math.PI;
                {audio_init_js}
            }});

            const audio = document.getElementById("vrm-audio");
            const btn = document.getElementById("play-btn");
            btn.onclick = () => {{ if(audio.src && audio.paused) {{ audio.currentTime = 0; audio.play(); btn.innerText = "ğŸ’¬ ë‹µë³€ ì¤‘..."; }} }};
            audio.onended = () => {{ btn.innerText = "ğŸ”„ ë‹¤ì‹œ ë“£ê¸°"; }};

            const clock = new THREE.Clock();
            function animate() {{
                requestAnimationFrame(animate);
                const delta = clock.getDelta();
                const time = clock.elapsedTime;

                if (vrm) {{
                    // --- [IDLE ë™ì‘ ë³µêµ¬] ---
                    const spine = vrm.humanoid.getNormalizedBoneNode('spine');
                    const neck = vrm.humanoid.getNormalizedBoneNode('neck');
                    const hips = vrm.humanoid.getNormalizedBoneNode('hips');

                    // ë¶€ë“œëŸ¬ìš´ í”ë“¤ë¦¼ íš¨ê³¼
                    if(spine) spine.rotation.x = Math.sin(time * 1.5) * 0.03; 
                    if(neck) neck.rotation.y = Math.sin(time * 0.7) * 0.05; 
                    if(hips) hips.position.y = Math.sin(time * 1.5) * 0.005;

                    vrm.update(delta);

                    // ë¦½ì‹±í¬ (ì… ëª¨ì–‘)
                    if (!audio.paused && !audio.ended && vrm.expressionManager) {{
                        const s = (Math.sin(Date.now() * 0.015) + 1) * 0.4;
                        ["aa", "oh", "Fcl_MTH_A", "Fcl_MTH_O"].forEach(k => {{
                            try {{ vrm.expressionManager.setValue(k, s); }} catch(e) {{}}
                        }});
                    }} else if (vrm.expressionManager) {{
                        ["aa","Fcl_MTH_A"].forEach(k => {{ try {{ vrm.expressionManager.setValue(k, 0); }} catch(e) {{}} }});
                    }}
                }}
                renderer.render(scene, camera);
            }}
            animate();
        </script>
    </div>
    """
    st.components.v1.html(html_code, height=640)

# (ì´í•˜ ë©”ì¸ í™”ë©´ êµ¬ì„± ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼í•©ë‹ˆë‹¤...)
st.title("ğŸ« ì„±ê¸€ê³  AI ë„ìš°ë¯¸")

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë´ ì£¼ì„¸ìš”. ğŸ˜Š"}]
if "current_audio" not in st.session_state:
    st.session_state.current_audio = None

col_chat, col_vrm = st.columns([3, 2])

with col_chat:
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]): st.markdown(msg["content"])
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"): st.markdown(prompt)
        with st.chat_message("assistant"):
            if chatbot:
                response = chatbot.ask(prompt)
                st.markdown(response)
                audio_bytes = text_to_speech(response)
                audio_base64 = get_audio_base64(audio_bytes)
                st.session_state.messages.append({"role": "assistant", "content": response})
                st.session_state.current_audio = audio_base64
                st.rerun()

with col_vrm:
    st.subheader("ğŸ­ AI ì•„ë°”íƒ€")
    vrm_viewer_component(st.session_state.current_audio)
