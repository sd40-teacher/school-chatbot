from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import create_retrieval_chain
from langchain.prompts import PromptTemplate

class SchoolChatbot:
    """ì„±ë™ê¸€ë¡œë²Œê²½ì˜ê³ ë“±í•™êµ AI ì±—ë´‡"""
    
    def __init__(self, api_key, docs_path="data/school_docs"):
        """
        ì±—ë´‡ ì´ˆê¸°í™”
        
        Args:
            api_key: OpenRouter API í‚¤
            docs_path: PDF ë¬¸ì„œê°€ ìˆëŠ” í´ë” ê²½ë¡œ
        """
        self.api_key = api_key
        self.docs_path = docs_path
        
        # OpenRouter LLM ì„¤ì • (ë¬´ë£Œ Gemini 2.0 Flash ëª¨ë¸)
        self.llm = ChatOpenAI(
            model="google/gemini-2.0-flash-exp:free",
            openai_api_key=api_key,
            openai_api_base="https://openrouter.ai/api/v1",
            default_headers={
                "HTTP-Referer": "https://sdglobal.sen.hs.kr/",
                "X-Title": "ì„±ë™ê¸€ë¡œë²Œê²½ì˜ê³  AI ì±—ë´‡"
            },
            temperature=0.7,
            max_tokens=1000
        )
        
        # ì„ë² ë”© ëª¨ë¸ ì„¤ì •
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            openai_api_key=api_key,
            openai_api_base="https://openrouter.ai/api/v1"
        )
        
        # ë¬¸ì„œ ë¡œë“œ ë° ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        self.vectorstore = self._load_documents()
        
        # QA ì²´ì¸ ìƒì„±
        self.qa_chain = self._create_qa_chain()
    
    def _load_documents(self):
        """PDF ë¬¸ì„œ ë¡œë“œ ë° ë²¡í„°í™”"""
        print(f"ğŸ“‚ {self.docs_path}ì—ì„œ PDF ë¬¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
        
        # PDF ë¡œë”
        loader = PyPDFDirectoryLoader(self.docs_path)
        documents = loader.load()
        
        if not documents:
            raise ValueError(
                f"âš ï¸ {self.docs_path} í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!\n"
                f"data/school_docs/ í´ë”ì— í•™êµ ì†Œê°œ PDFë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
            )
        
        print(f"âœ… {len(documents)}ê°œì˜ ë¬¸ì„œ í˜ì´ì§€ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        
        # í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,        # ê° ì²­í¬ì˜ í¬ê¸°
            chunk_overlap=200,      # ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¶€ë¶„
            length_function=len,
            separators=["\n\n", "\n", " ", ""]
        )
        splits = text_splitter.split_documents(documents)
        
        print(f"âœ… ë¬¸ì„œë¥¼ {len(splits)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.")
        
        # FAISS ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        print("ğŸ”„ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        vectorstore = FAISS.from_documents(splits, self.embeddings)
        
        print("âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ!")
        
        return vectorstore
    
    def _create_qa_chain(self):
        """ì§ˆì˜ì‘ë‹µ ì²´ì¸ ìƒì„±"""
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        prompt_template = """ë‹¹ì‹ ì€ ì„±ë™ê¸€ë¡œë²Œê²½ì˜ê³ ë“±í•™êµë¥¼ ì†Œê°œí•˜ëŠ” ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

ì•„ë˜ ì œê³µëœ í•™êµ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìƒ, í•™ë¶€ëª¨, ë°©ë¬¸ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ë‹µë³€ ì‹œ ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¼ì£¼ì„¸ìš”:
1. ì¹œì ˆí•˜ê³  ì •ì¤‘í•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
2. ì œê³µëœ ë¬¸ì„œì˜ ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
3. êµ¬ì²´ì ì´ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”
4. ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” "ì œê³µëœ ìë£Œì—ëŠ” í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. í•™êµì— ì§ì ‘ ë¬¸ì˜í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤ (02-2252-1932)"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”
5. ê°€ëŠ¥í•˜ë©´ ì˜ˆì‹œë‚˜ ë¶€ì—° ì„¤ëª…ì„ ì¶”ê°€í•˜ì„¸ìš”

í•™êµ ì •ë³´:
- í•™êµëª…: ì„±ë™ê¸€ë¡œë²Œê²½ì˜ê³ ë“±í•™êµ
- ì£¼ì†Œ: ì„œìš¸ ì¤‘êµ¬ í‡´ê³„ë¡œ 375 (ì‹ ë‹¹ë™)
- ì „í™”: 02-2252-1932
- í™ˆí˜ì´ì§€: https://sdglobal.sen.hs.kr/

ë¬¸ì„œ ë‚´ìš©:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""

        PROMPT = PromptTemplate(
            template=prompt_template,
            input_variables=["context", "question"]
        )
        
        # RetrievalQA ì²´ì¸ ìƒì„±
        qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 3}  # ìƒìœ„ 3ê°œì˜ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            ),
            return_source_documents=False,
            chain_type_kwargs={"prompt": PROMPT}
        )
        
        return qa_chain
    
    def ask(self, question):
        """
        ì§ˆë¬¸ì— ë‹µë³€
        
        Args:
            question: ì‚¬ìš©ìì˜ ì§ˆë¬¸
            
        Returns:
            str: AIì˜ ë‹µë³€
        """
        try:
            response = self.qa_chain.invoke({"query": question})
            return response["result"]
        except Exception as e:
            error_message = (
                f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n"
                f"ì˜¤ë¥˜ ë‚´ìš©: {str(e)}\n\n"
                f"í•™êµì— ì§ì ‘ ë¬¸ì˜í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n"
                f"ğŸ“ 02-2252-1932"
            )
            return error_message
    
    def refresh_documents(self):
        """
        ë¬¸ì„œ ìƒˆë¡œê³ ì¹¨ (PDF ì—…ë°ì´íŠ¸ ì‹œ ì‚¬ìš©)
        
        ì´ ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ë©´ data/school_docs í´ë”ì˜
        PDFë¥¼ ë‹¤ì‹œ ë¡œë“œí•˜ê³  ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì¬ìƒì„±í•©ë‹ˆë‹¤.
        """
        print("ğŸ”„ ë¬¸ì„œë¥¼ ë‹¤ì‹œ ë¡œë“œí•©ë‹ˆë‹¤...")
        self.vectorstore = self._load_documents()
        self.qa_chain = self._create_qa_chain()
        print("âœ… ë¬¸ì„œ ìƒˆë¡œê³ ì¹¨ ì™„ë£Œ!")
