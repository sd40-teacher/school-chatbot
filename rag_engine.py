import os
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

class SchoolChatbot:
    """ì„±ë™ê¸€ë¡œë²Œê²½ì˜ê³ ë“±í•™êµ AI ì±—ë´‡ì˜ ë‘ë‡Œ"""
    
    def __init__(self, api_key, docs_path="data/school_docs"):
        self.api_key = api_key
        self.docs_path = docs_path
        
        # 1. ëª¨ë¸ ì„¤ì • (OpenRouter Gemini)
        self.llm = ChatOpenAI(
            model="google/gemini-2.0-flash-exp:free",
            openai_api_key=api_key,
            openai_api_base="https://openrouter.ai/api/v1",
            temperature=0.7
        )
        
        # 2. ì„ë² ë”© ì„¤ì •
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            openai_api_key=api_key,
            openai_api_base="https://openrouter.ai/api/v1"
        )
        
        # 3. ë°ì´í„° ë¡œë“œ ë° ë²¡í„° ì €ì¥ì†Œ ìƒì„±
        self.vectorstore = self._load_documents()
        self.retriever = self.vectorstore.as_retriever(search_kwargs={"k": 3})
        
        # 4. ë‹µë³€ ì²´ì¸ ìƒì„±
        self.chain = self._create_chain()
    
    def _load_documents(self):
        """PDF ë¬¸ì„œë¥¼ ì½ì–´ì„œ AIê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜"""
        if not os.path.exists(self.docs_path):
            os.makedirs(self.docs_path)
            
        loader = PyPDFDirectoryLoader(self.docs_path)
        documents = loader.load()
        
        # [ë””ë²„ê¹…] íŒŒì¼ì„ ëª‡ í˜ì´ì§€ë‚˜ ì½ì—ˆëŠ”ì§€ í™•ì¸
        print(f"ğŸ“„ ë¡œë“œëœ ì´ í˜ì´ì§€ ìˆ˜: {len(documents)}")
        
        if not documents:
            raise ValueError(
                f"âš ï¸ '{self.docs_path}' í´ë”ì— PDF íŒŒì¼ì´ ì—†ê±°ë‚˜ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                "íŒŒì¼ëª…ì„ ì˜ë¬¸(ì˜ˆ: school_info.pdf)ìœ¼ë¡œ ë°”ê¿”ì„œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”."
            )
        
        # í…ìŠ¤íŠ¸ ë‚˜ëˆ„ê¸°
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(documents)
        
        print(f"âœ‚ï¸ ë¶„í• ëœ ë°ì´í„° ì¡°ê°(Chunk) ìˆ˜: {len(splits)}")
        
        return FAISS.from_documents(splits, self.embeddings)
    
    def _create_chain(self):
        """ì§ˆë¬¸ì„ ë°›ì•˜ì„ ë•Œ ë‹µì„ ìƒì„±í•˜ëŠ” íë¦„ ì„¤ê³„"""
        template = """ë‹¹ì‹ ì€ ì„±ë™ê¸€ë¡œë²Œê²½ì˜ê³ ë“±í•™êµë¥¼ ì†Œê°œí•˜ëŠ” ì¹œì ˆí•œ AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. 
ì•„ë˜ ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”. ëª¨ë¥´ë©´ í•™êµ(02-2252-1932)ë¡œ ë¬¸ì˜í•˜ë¼ê³  í•˜ì„¸ìš”.

ì •ë³´:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""
        prompt = ChatPromptTemplate.from_template(template)
        
        # ê°€ê³µ í•¨ìˆ˜
        def format_docs(docs):
            return "\n\n".join(doc.page_content for doc in docs)

        # LCEL íŒŒì´í”„ë¼ì¸ êµ¬ì„±
        chain = (
            {"context": self.retriever | format_docs, "question": RunnablePassthrough()}
            | prompt
            | self.llm
            | StrOutputParser()
        )
        return chain
    
    def ask(self, question):
        """ì‚¬ìš©ìê°€ ì§ˆë¬¸í•˜ë©´ ë‹µë³€ì„ ë°˜í™˜"""
        try:
            return self.chain.invoke(question)
        except Exception as e:
            return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
